{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9a7211-ef97-4e16-9f75-5bcc9675c629",
   "metadata": {},
   "source": [
    "### Lung Cancer Detection using CNNs\n",
    "This project uses CNN models for detecting lung cancer from CT scan images. It includes data preprocessing, augmentation, model architecture, training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a82de49-9fbf-49d5-852f-7da37f9956a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Imports and Setup\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Activation, AveragePooling2D, Concatenate, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4212995-b342-4ef3-a3bc-265a4215dcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cbb3a4-944d-4ba7-8b93-ace690ce6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Allow memory growth on the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpu_available = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e1f48db-eb9f-4550-99b3-eb4c226c311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "Found 315 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define Hyperparameters\n",
    "image_height, image_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Use raw strings (prefixing with r) or replace backslashes with forward slashes\n",
    "train_dir = r\"C:\\Users\\anant\\Downloads\\archive\\Data\\train\"\n",
    "val_dir = r\"C:\\Users\\anant\\Downloads\\archive\\Data\\valid\"\n",
    "test_dir = r\"C:\\Users\\anant\\Downloads\\archive\\Data\\test\"\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_data = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae1d26e-9dcd-4296-986f-659442791372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5. Define Identity and Convolutional Blocks\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    x = Conv2D(filters1, (1, 1), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "#6. Define ResNet-like Model and Custom Model\n",
    "\n",
    "def reuse_learning(input_shape=(224, 224, 3), include_top=False):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = conv_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    for _ in range(2):\n",
    "        x = identity_block(x, 3, [64, 64, 256])\n",
    "    \n",
    "    x = conv_block(x, 3, [128, 128, 512])\n",
    "    for _ in range(3):\n",
    "        x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256, 1024])\n",
    "    for _ in range(5):\n",
    "        x = identity_block(x, 3, [256, 256, 1024])\n",
    "    \n",
    "    x = conv_block(x, 3, [512, 512, 2048])\n",
    "    for _ in range(2):\n",
    "        x = identity_block(x, 3, [512, 512, 2048])\n",
    "    \n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1000, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=img_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def chest_custom_model1(input_shape=(224, 224, 3)):\n",
    "    base_resnet = reuse_learning(input_shape, include_top=False)\n",
    "    \n",
    "    for layer in base_resnet.layers[:150]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_resnet(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "#7. Model Fusion, Compilation, and Callbacks\n",
    "\n",
    "def fuse_models(resnet_model, chest_custom_model1, input_shape=(224, 224, 3)):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    features1 = resnet_model(input_layer)\n",
    "    features2 = chest_custom_model1(input_layer)\n",
    "    flattened_features1 = Flatten()(features1)\n",
    "    flattened_features2 = Flatten()(features2)\n",
    "    combined_features = Concatenate()([flattened_features1, flattened_features2])\n",
    "    x = Dense(1024, activation='relu')(combined_features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "model1 = reuse_learning(input_shape=(224, 224, 3), include_top=False) \n",
    "model2 = chest_custom_model1(input_shape=(224, 224, 3))\n",
    "model = fuse_models(model1, model2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dff8a51-b7b6-49de-a1ff-832055b01f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_models(resnet_model, chest_custom_model1, input_shape=(224, 224, 3)):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    features1 = resnet_model(input_layer)\n",
    "    features2 = chest_custom_model1(input_layer)\n",
    "    flattened_features1 = Flatten()(features1)\n",
    "    flattened_features2 = Flatten()(features2)\n",
    "    \n",
    "    combined_features = Concatenate()([flattened_features1, flattened_features2])\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(combined_features)\n",
    "    x = Dropout(0.6)(x)  # Increased dropout rate\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added more dense layer\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afbcd3a8-2a55-4fc5-8bf7-0e0fcbacfd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b61fa4-43cf-4509-8e67-06e3dd5bd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-4)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe53dc-e8c4-4b76-bc3c-5a41862e0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Training and Evaluation\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=200,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaea81a-febe-44ab-825d-11fe47173102",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

