{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6844799-83d4-48be-a26c-60d0b5439984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lung Cancer Detection using CNNs\n",
    "This project uses CNN models for detecting lung cancer from CT scan images. It includes data preprocessing, augmentation, model architecture, training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82de49-9fbf-49d5-852f-7da37f9956a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Imports and Setup\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Activation, AveragePooling2D, Concatenate, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf202532-b3cf-4473-a404-bcc66a92f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define Hyperparameters\n",
    "python\n",
    "Copy code\n",
    "image_height, image_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "train_dir = \"/path/to/train\"\n",
    "val_dir = \"/path/to/validation\"\n",
    "test_dir = \"/path/to/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f48db-eb9f-4550-99b3-eb4c226c311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Data Augmentation and Generators\n",
    "python\n",
    "Copy code\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_data = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1d26e-9dcd-4296-986f-659442791372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Define Identity and Convolutional Blocks\n",
    "python\n",
    "Copy code\n",
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    x = Conv2D(filters1, (1, 1), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "#6. Define ResNet-like Model and Custom Model\n",
    "python\n",
    "Copy code\n",
    "def reuse_learning(input_shape=(224, 224, 3), include_top=False):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = conv_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    for _ in range(2):\n",
    "        x = identity_block(x, 3, [64, 64, 256])\n",
    "    \n",
    "    x = conv_block(x, 3, [128, 128, 512])\n",
    "    for _ in range(3):\n",
    "        x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256, 1024])\n",
    "    for _ in range(5):\n",
    "        x = identity_block(x, 3, [256, 256, 1024])\n",
    "    \n",
    "    x = conv_block(x, 3, [512, 512, 2048])\n",
    "    for _ in range(2):\n",
    "        x = identity_block(x, 3, [512, 512, 2048])\n",
    "    \n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1000, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=img_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def chest_custom_model1(input_shape=(224, 224, 3)):\n",
    "    base_resnet = reuse_learning(input_shape, include_top=False)\n",
    "    \n",
    "    for layer in base_resnet.layers[:150]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_resnet(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "#7. Model Fusion, Compilation, and Callbacks\n",
    "python\n",
    "Copy code\n",
    "def fuse_models(resnet_model, chest_custom_model1, input_shape=(224, 224, 3)):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    features1 = resnet_model(input_layer)\n",
    "    features2 = chest_custom_model1(input_layer)\n",
    "    flattened_features1 = Flatten()(features1)\n",
    "    flattened_features2 = Flatten()(features2)\n",
    "    combined_features = Concatenate()([flattened_features1, flattened_features2])\n",
    "    x = Dense(1024, activation='relu')(combined_features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "model1 = reuse_learning(input_shape=(224, 224, 3), include_top=False)\n",
    "model2 = chest_custom_model1(input_shape=(224, 224, 3))\n",
    "model = fuse_models(model1, model2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-4)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "#8 Training and Evaluation\n",
    "python\n",
    "Copy code\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
